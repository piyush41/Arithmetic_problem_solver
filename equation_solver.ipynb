{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4Qd1egoJXHAG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fri Nov  4 12:33:49 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.141.03   Driver Version: 470.141.03   CUDA Version: 11.4     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:07:00.0 Off |                    0 |\n",
            "| N/A   30C    P0    54W / 400W |      0MiB / 40536MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "|   1  NVIDIA A100-SXM...  Off  | 00000000:0A:00.0 Off |                    0 |\n",
            "| N/A   27C    P0    54W / 400W |      0MiB / 40536MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "|   2  NVIDIA A100-SXM...  Off  | 00000000:45:00.0 Off |                    0 |\n",
            "| N/A   27C    P0    51W / 400W |      0MiB / 40536MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "|   3  NVIDIA A100-SXM...  Off  | 00000000:4B:00.0 Off |                    0 |\n",
            "| N/A   31C    P0    52W / 400W |      0MiB / 40536MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "|   4  NVIDIA A100-SXM...  Off  | 00000000:84:00.0 Off |                    0 |\n",
            "| N/A   31C    P0    55W / 400W |      0MiB / 40536MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "|   5  NVIDIA A100-SXM...  Off  | 00000000:8A:00.0 Off |                    0 |\n",
            "| N/A   28C    P0    51W / 400W |      0MiB / 40536MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "|   6  NVIDIA A100-SXM...  Off  | 00000000:C0:00.0 Off |                    0 |\n",
            "| N/A   28C    P0    52W / 400W |      0MiB / 40536MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "|   7  NVIDIA A100-SXM...  Off  | 00000000:C3:00.0 Off |                    0 |\n",
            "| N/A   31C    P0    55W / 400W |      0MiB / 40536MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# check for the GPU provided in the runtime\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-28tCMuZIn0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VswKj_dSqsY5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-11-04 12:33:56.128313: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-11-04 12:33:56.246630: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2022-11-04 12:33:56.781444: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
            "2022-11-04 12:33:56.781520: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
            "2022-11-04 12:33:56.781526: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.2.6\n"
          ]
        }
      ],
      "source": [
        "# mostly pl is used while doing complex model training\n",
        "import pytorch_lightning as pl\n",
        "print(pl.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6HRG-0vqZkbx"
      },
      "outputs": [],
      "source": [
        "# argparse makes it easier to write user friendly command line interfaces\n",
        "import argparse\n",
        "# package for faster file name matching\n",
        "import glob\n",
        "# makiing directories for data \n",
        "import os\n",
        "# reading json files as the data is present in json files\n",
        "import json\n",
        "# time module for calculating the model runtime\n",
        "import time\n",
        "# Allows writing status messages to a file\n",
        "import logging\n",
        "# generate random float numbers uniformly\n",
        "import random\n",
        "# regex module for text \n",
        "import re\n",
        "# module provides various functions which work on \n",
        "# iterators too produce complex iterators\n",
        "from itertools import chain\n",
        "from string import punctuation\n",
        "import torch.nn.functional as F\n",
        "# import torchtext\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "# pandas for data manipulation\n",
        "import pandas as pd\n",
        "# numpy for array operations\n",
        "import numpy as np\n",
        "# PyTorch\n",
        "import torch\n",
        "# provides various classes representing file system paths\n",
        "# with appropriate semantics\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "# import pytorch_lightning as pl\n",
        "\n",
        "# splitting the data \n",
        "from sklearn.model_selection import train_test_split\n",
        "# ANSII color formatting for ouput in terminal\n",
        "from termcolor import colored\n",
        "# wrapping paragraphs into string\n",
        "import textwrap\n",
        "\n",
        "from torch.optim import Adam\n",
        "\n",
        "# model checkpoints in pretrained model\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "'''\n",
        "optimizer - AdamW\n",
        "T5 Conditional Generator in which we'll give conditions\n",
        "T5 tokenizer because it is fast\n",
        "training the model without a learning rate\n",
        "'''\n",
        "from transformers import (\n",
        "    AdamW,\n",
        "    T5ForConditionalGeneration,\n",
        "    T5Tokenizer,\n",
        "    get_linear_schedule_with_warmup\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3g9RyS26ao6N"
      },
      "outputs": [],
      "source": [
        "# Seeds all the processes including numpy torch and other imported modules.\n",
        "# pl.seed_everything(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QLwmdXZwYBBD"
      },
      "outputs": [],
      "source": [
        "# # check the version provided by Lightning\n",
        "# import pytorch_lightning as pl\n",
        "# print(pl.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3GZAifg3a5qL"
      },
      "outputs": [],
      "source": [
        "# QA dataset from https://github.com/dmis-lab/bioasq-biobert\n",
        "# which is in Zip format\n",
        "# !gdown --id 1mxVUywvKzvA9bvrUc11RYuOTy7MYcXHF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KC2mQLy5bR81"
      },
      "outputs": [],
      "source": [
        "# Unzipping the folder\n",
        "# !unzip -q bio-QA.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_excel('ArithOpsTrain.xlsx',header=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Q8SO3M9vmJqL"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(979, 6)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "QveL85kXKZXS"
      },
      "outputs": [],
      "source": [
        "# Dropping all the rows with repeated context and questions pairs.\n",
        "\n",
        "# df = df.drop_duplicates(subset=[\"context\"]).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "UmHSVE-8KZaD"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(979, 6)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Description</th>\n",
              "      <th>Question</th>\n",
              "      <th>Equation</th>\n",
              "      <th>Input Numbers</th>\n",
              "      <th>Output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>gino has number0 popsicle sticks . i have numb...</td>\n",
              "      <td>what is the sum of our popsicle sticks ?</td>\n",
              "      <td>+ number0 number1</td>\n",
              "      <td>63 50</td>\n",
              "      <td>113.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>lino picked up number0 shells at the seashore ...</td>\n",
              "      <td>how many shells did he pick up in all ?</td>\n",
              "      <td>+ number0 number1</td>\n",
              "      <td>292 324</td>\n",
              "      <td>616.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>there were number0 parents in the program and ...</td>\n",
              "      <td>how many people were present in the program ?</td>\n",
              "      <td>+ number0 number1</td>\n",
              "      <td>105 698</td>\n",
              "      <td>803.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>last saturday marie sold number0 magazines and...</td>\n",
              "      <td>what is the total number of reading materials ...</td>\n",
              "      <td>+ number0 number1</td>\n",
              "      <td>425 275</td>\n",
              "      <td>700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>there are number0 birds on the fence . number1...</td>\n",
              "      <td>how many birds are on the fence ?</td>\n",
              "      <td>+ number0 number1</td>\n",
              "      <td>12 8</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                        Description  \\\n",
              "0         NaN  gino has number0 popsicle sticks . i have numb...   \n",
              "1         NaN  lino picked up number0 shells at the seashore ...   \n",
              "2         NaN  there were number0 parents in the program and ...   \n",
              "3         NaN  last saturday marie sold number0 magazines and...   \n",
              "4         NaN  there are number0 birds on the fence . number1...   \n",
              "\n",
              "                                            Question           Equation  \\\n",
              "0           what is the sum of our popsicle sticks ?  + number0 number1   \n",
              "1            how many shells did he pick up in all ?  + number0 number1   \n",
              "2      how many people were present in the program ?  + number0 number1   \n",
              "3  what is the total number of reading materials ...  + number0 number1   \n",
              "4                  how many birds are on the fence ?  + number0 number1   \n",
              "\n",
              "  Input Numbers  Output  \n",
              "0         63 50   113.0  \n",
              "1       292 324   616.0  \n",
              "2       105 698   803.0  \n",
              "3       425 275   700.0  \n",
              "4          12 8    20.0  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.rename(columns = {'Description':'context','Question':'question','Equation':'answer_text'}, inplace = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>answer_text</th>\n",
              "      <th>Input Numbers</th>\n",
              "      <th>Output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>gino has number0 popsicle sticks . i have numb...</td>\n",
              "      <td>what is the sum of our popsicle sticks ?</td>\n",
              "      <td>+ number0 number1</td>\n",
              "      <td>63 50</td>\n",
              "      <td>113.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>lino picked up number0 shells at the seashore ...</td>\n",
              "      <td>how many shells did he pick up in all ?</td>\n",
              "      <td>+ number0 number1</td>\n",
              "      <td>292 324</td>\n",
              "      <td>616.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>there were number0 parents in the program and ...</td>\n",
              "      <td>how many people were present in the program ?</td>\n",
              "      <td>+ number0 number1</td>\n",
              "      <td>105 698</td>\n",
              "      <td>803.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>last saturday marie sold number0 magazines and...</td>\n",
              "      <td>what is the total number of reading materials ...</td>\n",
              "      <td>+ number0 number1</td>\n",
              "      <td>425 275</td>\n",
              "      <td>700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>there are number0 birds on the fence . number1...</td>\n",
              "      <td>how many birds are on the fence ?</td>\n",
              "      <td>+ number0 number1</td>\n",
              "      <td>12 8</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>974</th>\n",
              "      <td>NaN</td>\n",
              "      <td>there are number0 bananas in janice 's banana ...</td>\n",
              "      <td>how big is each group ?</td>\n",
              "      <td>/ number0 number2</td>\n",
              "      <td>3300 5 75</td>\n",
              "      <td>44.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>975</th>\n",
              "      <td>NaN</td>\n",
              "      <td>janice has number0 bottle caps that must be pu...</td>\n",
              "      <td>how many bottle caps must go in each box ?</td>\n",
              "      <td>/ number0 number2</td>\n",
              "      <td>316 17 79</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>976</th>\n",
              "      <td>NaN</td>\n",
              "      <td>chris is inviting number0 friends to a party ....</td>\n",
              "      <td>how many cookies will each friend get ?</td>\n",
              "      <td>/ number1 number0</td>\n",
              "      <td>82 1804 10</td>\n",
              "      <td>22.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>977</th>\n",
              "      <td>NaN</td>\n",
              "      <td>keith has number0 marbles and number1 pencils ...</td>\n",
              "      <td>how many marbles does each friend get ?</td>\n",
              "      <td>/ number0 number2</td>\n",
              "      <td>5530 3 79</td>\n",
              "      <td>70.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>978</th>\n",
              "      <td>NaN</td>\n",
              "      <td>there are number0 students and number1 apples ...</td>\n",
              "      <td>how many does each student get ?</td>\n",
              "      <td>/ number1 number0</td>\n",
              "      <td>43 1720 9</td>\n",
              "      <td>40.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>979 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0                                            context  \\\n",
              "0           NaN  gino has number0 popsicle sticks . i have numb...   \n",
              "1           NaN  lino picked up number0 shells at the seashore ...   \n",
              "2           NaN  there were number0 parents in the program and ...   \n",
              "3           NaN  last saturday marie sold number0 magazines and...   \n",
              "4           NaN  there are number0 birds on the fence . number1...   \n",
              "..          ...                                                ...   \n",
              "974         NaN  there are number0 bananas in janice 's banana ...   \n",
              "975         NaN  janice has number0 bottle caps that must be pu...   \n",
              "976         NaN  chris is inviting number0 friends to a party ....   \n",
              "977         NaN  keith has number0 marbles and number1 pencils ...   \n",
              "978         NaN  there are number0 students and number1 apples ...   \n",
              "\n",
              "                                              question        answer_text  \\\n",
              "0             what is the sum of our popsicle sticks ?  + number0 number1   \n",
              "1              how many shells did he pick up in all ?  + number0 number1   \n",
              "2        how many people were present in the program ?  + number0 number1   \n",
              "3    what is the total number of reading materials ...  + number0 number1   \n",
              "4                    how many birds are on the fence ?  + number0 number1   \n",
              "..                                                 ...                ...   \n",
              "974                            how big is each group ?  / number0 number2   \n",
              "975         how many bottle caps must go in each box ?  / number0 number2   \n",
              "976            how many cookies will each friend get ?  / number1 number0   \n",
              "977            how many marbles does each friend get ?  / number0 number2   \n",
              "978                   how many does each student get ?  / number1 number0   \n",
              "\n",
              "    Input Numbers  Output  \n",
              "0           63 50   113.0  \n",
              "1         292 324   616.0  \n",
              "2         105 698   803.0  \n",
              "3         425 275   700.0  \n",
              "4            12 8    20.0  \n",
              "..            ...     ...  \n",
              "974     3300 5 75    44.0  \n",
              "975     316 17 79     4.0  \n",
              "976    82 1804 10    22.0  \n",
              "977     5530 3 79    70.0  \n",
              "978     43 1720 9    40.0  \n",
              "\n",
              "[979 rows x 6 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-rvJMpNt5Zo"
      },
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "l2ozZ4ptoYAN"
      },
      "outputs": [],
      "source": [
        "# using the base T5 model having 222M params\n",
        "MODEL_NAME ='t5-base'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "HrtKKzO8pHAL"
      },
      "outputs": [],
      "source": [
        "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_tokens = [\"number0\",'number1','number2']\n",
        "\n",
        "tokenizer.add_tokens(new_tokens,special_tokens=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "sam=tokenizer('piyush number0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[2816, 63, 8489, 32100, 1]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sam['input_ids']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "hKxWSsdupHC2"
      },
      "outputs": [],
      "source": [
        "sample_encoding = tokenizer('is the glass half empty or half full?', 'It depends on the initial state of the glass. If the glass starts out empty and liquid is added until it is half full, it is half full. If the glass starts out full and liquid is removed until it is half empty, it is half empty.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "83i_WzPGpyJR"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask'])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_encoding.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "DWJlEbtLp1ap"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[19, 8, 1905, 985, 6364, 42, 985, 423, 58, 1, 94, 5619, 30, 8, 2332, 538, 13, 8, 1905, 5, 156, 8, 1905, 3511, 91, 6364, 11, 4400, 19, 974, 552, 34, 19, 985, 423, 6, 34, 19, 985, 423, 5, 156, 8, 1905, 3511, 91, 423, 11, 4400, 19, 3641, 552, 34, 19, 985, 6364, 6, 34, 19, 985, 6364, 5, 1]\n"
          ]
        }
      ],
      "source": [
        "print(sample_encoding[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "rVEOLW6CqCCD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(sample_encoding[\"attention_mask\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "44fV5Mauvp-F"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "63 63\n"
          ]
        }
      ],
      "source": [
        "print(len(sample_encoding['input_ids']), len(sample_encoding['attention_mask']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "wIy8dTAJqFW0"
      },
      "outputs": [],
      "source": [
        "# Checking the decoding of the input ids\n",
        "\n",
        "preds = [\n",
        "         tokenizer.decode(input_id, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "         for input_id in sam['input_ids']\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "xi1xjpSVqeYc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pi y ush number0 </s>\n"
          ]
        }
      ],
      "source": [
        "preds= \" \".join(preds)\n",
        "for wrap in textwrap.wrap(preds, width = 80):\n",
        "  print(wrap)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Unnamed: 0                                                     NaN\n",
              "context          bryan had number0 precious stones in his colle...\n",
              "question                   how much money did bryan get in total ?\n",
              "answer_text                                      * number0 number1\n",
              "Input Numbers                                            8 1785.00\n",
              "Output                                                     14280.0\n",
              "Name: 243, dtype: object"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_question = df.iloc[243]\n",
        "sample_question"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHFoy6akwCAi"
      },
      "source": [
        "There exists a special seperator token in between the question and its answers.\n",
        "\n",
        "Checking the encoding on the sample question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "N2_zfw8xqgBf"
      },
      "outputs": [],
      "source": [
        "encoding = tokenizer(\n",
        "    sample_question['question'],\n",
        "    sample_question['context'],\n",
        "    max_length=396,\n",
        "    padding='max_length',\n",
        "    truncation=\"only_second\",\n",
        "    return_attention_mask=True,\n",
        "    add_special_tokens=True,\n",
        "    return_tensors=\"pt\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "SNgUeiafsQPX"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask'])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoding.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "6TCcHThUsXgt"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'eos_token': '</s>',\n",
              " 'unk_token': '<unk>',\n",
              " 'pad_token': '<pad>',\n",
              " 'additional_special_tokens': \"['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']\"}"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.special_tokens_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "myaSEq9vsd20"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('</s>', 1)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "tokenizer.eos_token, tokenizer.eos_token_id\n",
        "# Input id of 1 represents end of sequence token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ND-qMS3MsssL"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'how much money did bryan get in total?</s> bryan had number0 precious stones in his collection which he sold to his friend from the jewelry store. if the stones were sold at $ number1 each</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>'"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Text representation pf the input ids\n",
        "\n",
        "tokenizer.decode(encoding['input_ids'].squeeze())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4O94b5A7wfMw"
      },
      "source": [
        "## Creating the labels for the answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "TArh_28mtGRC"
      },
      "outputs": [],
      "source": [
        "answer_encoding = tokenizer(\n",
        "    sample_question['answer_text'],\n",
        "    max_length=32,\n",
        "    padding='max_length',\n",
        "    truncation=True,\n",
        "    return_attention_mask=True,\n",
        "    add_special_tokens=True,\n",
        "    return_tensors=\"pt\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "1MhbXR76tZJK"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'* number0 number1 </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>'"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.decode(answer_encoding['input_ids'].squeeze())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "p3q5mC44tfSx"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1429, 32100, 32101,     1,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0]])"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels = answer_encoding[\"input_ids\"]\n",
        "labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PiJpR5cwuPI"
      },
      "source": [
        "Labels after the end of sequence in the answer encoding has to be converted to -100 from 0 for the model evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "ocbgT0JDueVZ"
      },
      "outputs": [],
      "source": [
        "labels[labels == 0] = -100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "8qIroGAVulLI"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1429, 32100, 32101,     1,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "          -100,  -100]])"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0OrBRcPuodP"
      },
      "source": [
        "## To create dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "YC84KMKxuqFN"
      },
      "outputs": [],
      "source": [
        "class BioQADataset(Dataset):\n",
        "  def __init__(\n",
        "      self,\n",
        "      data:pd.DataFrame,\n",
        "      tokenizer:T5Tokenizer,\n",
        "      source_max_token_len: int = 396,\n",
        "      target_max_token_len: int = 32,\n",
        "\n",
        "      ):\n",
        "    \n",
        "    self.data =  data\n",
        "    self.tokenizer =  tokenizer\n",
        "    self.source_max_token_len =  source_max_token_len\n",
        "    self.target_max_token_len =  target_max_token_len\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, index: int):\n",
        "    data_row = self.data.iloc[index]\n",
        "\n",
        "    source_encoding = tokenizer(\n",
        "      data_row['question'],\n",
        "      data_row['context'],\n",
        "      max_length=self.source_max_token_len,\n",
        "      padding='max_length',\n",
        "      \n",
        "      \n",
        "      return_attention_mask=True,\n",
        "      add_special_tokens=True,\n",
        "      return_tensors=\"pt\"\n",
        "      )\n",
        "    \n",
        "    target_encoding = tokenizer(\n",
        "      data_row['answer_text'],\n",
        "      max_length=self.target_max_token_len,\n",
        "      padding='max_length',\n",
        "      truncation=True,\n",
        "      return_attention_mask=True,\n",
        "      add_special_tokens=True,\n",
        "      return_tensors=\"pt\"\n",
        "      )\n",
        "    \n",
        "    labels = target_encoding['input_ids']\n",
        "    labels[labels==0] = -100\n",
        "\n",
        "    return dict(\n",
        "        question=data_row['question'],\n",
        "        context=data_row['context'],\n",
        "        answer_text=data_row['answer_text'],\n",
        "        input_ids=source_encoding[\"input_ids\"].flatten(),\n",
        "        attention_mask=source_encoding['attention_mask'].flatten(),\n",
        "        labels=labels.flatten()\n",
        "    )\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "hI-CMUtuxkZz"
      },
      "outputs": [],
      "source": [
        "sample_dataset = BioQADataset(df, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "eIfXyyObx3Kq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question:  what is the sum of our popsicle sticks ?\n",
            "Answer text:  + number0 number1\n",
            "Input_ids:  tensor([ 125,   19,    8, 4505,   13,   69, 2783,    7,   23, 2482])\n",
            "Labels:  tensor([ 1768, 32100, 32101,     1,  -100,  -100,  -100,  -100,  -100,  -100])\n"
          ]
        }
      ],
      "source": [
        "for data in sample_dataset:\n",
        "  print(\"Question: \", data['question'])\n",
        "  print(\"Answer text: \", data['answer_text'])\n",
        "  print(\"Input_ids: \", data['input_ids'][:10])\n",
        "  print(\"Labels: \", data['labels'][:10])\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vD8JFfYJxCcl"
      },
      "source": [
        "## Splitting into train and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "xXOHeMUVyIYS"
      },
      "outputs": [],
      "source": [
        "train_df, val_df = train_test_split(df, test_size=0.05)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "-Wv5RMMlyyvs"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((930, 6), (49, 6))"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.shape,  val_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uyNj_lcy73E"
      },
      "source": [
        "# Create pytorch lightning datamodule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "ZLGivrpDy9ph"
      },
      "outputs": [],
      "source": [
        "class BioDataModule(nn.Module):\n",
        "  def __init__(\n",
        "      self,\n",
        "      train_df: pd.DataFrame,\n",
        "      test_df: pd.DataFrame,\n",
        "      tokenizer:T5Tokenizer,\n",
        "      batch_size: int = 8,\n",
        "      source_max_token_len: int = 396,\n",
        "      target_max_token_len: int = 32,\n",
        "      ):\n",
        "    super().__init__()\n",
        "    self.train_df = train_df\n",
        "    self.test_df = test_df\n",
        "    self.tokenizer = tokenizer\n",
        "    self.batch_size = batch_size\n",
        "    self.source_max_token_len = source_max_token_len\n",
        "    self.target_max_token_len = target_max_token_len\n",
        "\n",
        "  def setup(self):\n",
        "    self.train_dataset = BioQADataset(\n",
        "        self.train_df,\n",
        "        self.tokenizer,\n",
        "        self.source_max_token_len,\n",
        "        self.target_max_token_len\n",
        "        )\n",
        "\n",
        "    self.test_dataset = BioQADataset(\n",
        "    self.test_df,\n",
        "    self.tokenizer,\n",
        "    self.source_max_token_len,\n",
        "    self.target_max_token_len\n",
        "    )\n",
        " \n",
        "  def train_dataloader(self):\n",
        "    return DataLoader(\n",
        "        self.train_dataset,\n",
        "        batch_size=self.batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=4\n",
        "        )\n",
        "  def val_dataloader(self):\n",
        "    return DataLoader(\n",
        "        self.test_dataset,\n",
        "        batch_size=self.batch_size,\n",
        "        num_workers=4\n",
        "        )\n",
        "\n",
        "  def test_dataloader(self):\n",
        "    return DataLoader(\n",
        "        self.test_dataset,\n",
        "        batch_size=1,\n",
        "        num_workers=4\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "RCgqZshX2CLy"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE =4\n",
        "N_EPOCHS = 6\n",
        "\n",
        "data_module = BioDataModule(train_df, val_df, tokenizer, batch_size=BATCH_SIZE)\n",
        "data_module.setup()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_loader=data_module.train_dataloader()\n",
        "valid_loader =data_module.val_dataloader()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "dict_keys(['question', 'context', 'answer_text', 'input_ids', 'attention_mask', 'labels'])\n"
          ]
        }
      ],
      "source": [
        "for batch_idx, batch in enumerate(valid_loader):\n",
        "    print(batch_idx)\n",
        "    print(batch.keys())\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "233"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(valid_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Og0JGVoIxdce"
      },
      "source": [
        "## Loading and finetuning the T5-base model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOQCsI_RSrsI"
      },
      "source": [
        "## Building the PyTorch lightning module using T5ForConditionalGeneration model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "7yu2hpq8SLOi"
      },
      "outputs": [],
      "source": [
        "class BioQAModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME, return_dict=True)\n",
        "\n",
        "\n",
        "  def forward(self, input_ids, attention_mask, labels=None):\n",
        "    output = self.model(\n",
        "        input_ids, \n",
        "        attention_mask=attention_mask,\n",
        "        labels=labels)\n",
        "\n",
        "    return output.loss, output.logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "uX2RY1vK1YVr"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at t5-base were not used when initializing T5ForConditionalGeneration: ['decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight']\n",
            "- This IS expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BioQAModel(\n",
              "  (model): T5ForConditionalGeneration(\n",
              "    (shared): Embedding(32128, 768)\n",
              "    (encoder): T5Stack(\n",
              "      (embed_tokens): Embedding(32128, 768)\n",
              "      (block): ModuleList(\n",
              "        (0): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (relative_attention_bias): Embedding(32, 12)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (2): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (3): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (4): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (5): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (6): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (7): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (8): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (9): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (10): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (11): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_layer_norm): T5LayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (decoder): T5Stack(\n",
              "      (embed_tokens): Embedding(32128, 768)\n",
              "      (block): ModuleList(\n",
              "        (0): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (relative_attention_bias): Embedding(32, 12)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (2): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (3): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (4): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (5): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (6): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (7): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (8): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (9): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (10): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (11): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_layer_norm): T5LayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DEVICE = torch.device('cuda:4' if torch.cuda.is_available() else 'cpu')\n",
        "model = BioQAModel() \n",
        "optim = torch.optim.AdamW(model.parameters(),lr=0.0001 )\n",
        "model.to(DEVICE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "next(model.parameters()).is_cuda\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_answer(question):\n",
        "  source_encoding=tokenizer(\n",
        "      question[\"question\"],\n",
        "      question['context'],\n",
        "      max_length = 396,\n",
        "      padding=\"max_length\",\n",
        "      truncation=\"only_second\",\n",
        "      return_attention_mask=True,\n",
        "      add_special_tokens=True,\n",
        "      return_tensors=\"pt\"\n",
        "\n",
        "  ).to(DEVICE)\n",
        "\n",
        "  generated_ids = model.model.generate(\n",
        "      input_ids=source_encoding[\"input_ids\"],\n",
        "      attention_mask=source_encoding[\"attention_mask\"],\n",
        "      num_beams=1,  # greedy search\n",
        "      max_length=80,\n",
        "      repetition_penalty=2.5,\n",
        "      early_stopping=True,\n",
        "      use_cache=True)\n",
        "  \n",
        "  preds = [\n",
        "          tokenizer.decode(generated_id, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "          for generated_id in generated_ids\n",
        "  ]\n",
        "\n",
        "  return \"\".join(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        " \n",
        " \n",
        "def evaluate(expression,numbers_array):\n",
        "    \"\"\"\n",
        "    Evaluate a given expression in prefix notation.\n",
        "    Asserts that the given expression is valid.\n",
        "    \"\"\"\n",
        "    stack = []\n",
        "    sp=['+','-','*','/']\n",
        "\n",
        "    # iterate over the string in reverse order\n",
        "    for c in expression[::-1]:\n",
        " \n",
        "        # push operand to stack\n",
        "        if c in sp:\n",
        "            # pop values from stack can calculate the result\n",
        "            # push the result onto the stack again\n",
        "            if len(stack)<2:\n",
        "                return 0,-1\n",
        "            o1 = stack.pop()\n",
        "            o2 = stack.pop()\n",
        " \n",
        "            if c == '+':\n",
        "                stack.append(o1 + o2)\n",
        " \n",
        "            elif c == '-':\n",
        "                stack.append(o1 - o2)\n",
        " \n",
        "            elif c == '*':\n",
        "                stack.append(o1 * o2)\n",
        " \n",
        "            elif c == '/':\n",
        "                stack.append(o1 / o2)\n",
        "        else:\n",
        "            no_index=c[-1]\n",
        "            if(no_index.isdigit() and int(no_index)<len(numbers_array)) :\n",
        "                stack.append(float(numbers_array[int(no_index)]))\n",
        "    if len(stack)!=1:\n",
        "        return 0,-1\n",
        "    return 1,stack.pop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "def infer(dataframe):\n",
        "    count=0\n",
        "    for index in range(dataframe.shape[0]):\n",
        "        # if count!=index:\n",
        "        #     print(index)\n",
        "        sample_quest = dataframe.iloc[index]\n",
        "        truth=sample_quest[\"answer_text\"].split()\n",
        "        # print(truth)\n",
        "        no=sample_quest['Input Numbers'].split()\n",
        "        # print(no)\n",
        "        predicted=generate_answer(sample_quest).split()\n",
        "        actual=sample_quest['Output']\n",
        "        # print(predicted)\n",
        "        bool1,val1=evaluate(truth,no)\n",
        "        bool2,val2=evaluate(predicted,no)\n",
        "        # print(bool1,val1)\n",
        "        # print(bool2,val2)\n",
        "        if(bool2==1):\n",
        "            if(round(val2,2)==round(actual,2)):\n",
        "                count=count+1\n",
        "            # else:\n",
        "            #     print(index)\n",
        "    return count/dataframe.shape[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validation_loss(model, data_loader, device):\n",
        "    loss_val=0\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # correct_pred, num_examples = 0, 0\n",
        "\n",
        "        for batch_idx, batch in enumerate(data_loader):\n",
        "\n",
        "            ### Prepare data\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "            \n",
        "            loss,outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            # loss, logits = outputs['loss'], outputs['logits']\n",
        "            loss_val=loss_val+loss\n",
        "            # _, predicted_labels = torch.max(logits, 1)\n",
        "\n",
        "            # num_examples += labels.size(0)\n",
        "\n",
        "            # correct_pred += (predicted_labels == labels).sum()\n",
        "    return loss_val/len(data_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########################################################################################\n",
            "current Epoch is  1\n",
            "training loss  tensor(4.5310, device='cuda:4', grad_fn=<DivBackward0>)\n",
            "validation Loss tensor(2.6238, device='cuda:4')\n",
            "validation Accuracy 0.3673469387755102\n",
            "The Training accuracy 0.4096774193548387\n",
            "Time elapsed: 1.61 min\n",
            "########################################################################################\n",
            "current Epoch is  2\n",
            "training loss  tensor(2.2388, device='cuda:4', grad_fn=<DivBackward0>)\n",
            "validation Loss tensor(1.8178, device='cuda:4')\n",
            "validation Accuracy 0.42857142857142855\n",
            "Time elapsed: 2.16 min\n",
            "########################################################################################\n",
            "current Epoch is  3\n",
            "training loss  tensor(1.7143, device='cuda:4', grad_fn=<DivBackward0>)\n",
            "validation Loss tensor(1.2553, device='cuda:4')\n",
            "validation Accuracy 0.4897959183673469\n",
            "Time elapsed: 2.72 min\n",
            "########################################################################################\n",
            "current Epoch is  4\n",
            "training loss  tensor(1.3197, device='cuda:4', grad_fn=<DivBackward0>)\n",
            "validation Loss tensor(1.1168, device='cuda:4')\n",
            "validation Accuracy 0.5102040816326531\n",
            "Time elapsed: 3.28 min\n",
            "########################################################################################\n",
            "current Epoch is  5\n",
            "training loss  tensor(1.1333, device='cuda:4', grad_fn=<DivBackward0>)\n",
            "validation Loss tensor(1.0048, device='cuda:4')\n",
            "validation Accuracy 0.5102040816326531\n",
            "Time elapsed: 3.82 min\n",
            "########################################################################################\n",
            "current Epoch is  6\n",
            "training loss  tensor(0.9050, device='cuda:4', grad_fn=<DivBackward0>)\n",
            "validation Loss tensor(0.8521, device='cuda:4')\n",
            "validation Accuracy 0.5306122448979592\n",
            "Time elapsed: 4.36 min\n",
            "########################################################################################\n",
            "current Epoch is  7\n"
          ]
        }
      ],
      "source": [
        "from sklearn.utils import validation\n",
        "\n",
        "\n",
        "NUM_EPOCHS=50\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    print(\"########################################################################################\")\n",
        "    print(\"current Epoch is \", epoch+1)\n",
        "    model.train()\n",
        "    curr_loss=0\n",
        "    for batch_idx, batch in enumerate(train_loader):\n",
        "        \n",
        "        ### Prepare data\n",
        "        input_ids = batch['input_ids'].to(DEVICE)\n",
        "        attention_mask = batch['attention_mask'].to(DEVICE)\n",
        "        labels = batch['labels'].to(DEVICE)\n",
        "\n",
        "        ### Forward\n",
        "        loss,outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        # loss, logits = outputs['loss'], outputs['logits']\n",
        "        curr_loss =curr_loss+loss\n",
        "        ### Backward\n",
        "        optim.zero_grad()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        \n",
        "        ### Logging\n",
        "        # if not batch_idx % 250:\n",
        "        #     print (f'Epoch: {epoch+1:04d}/{NUM_EPOCHS:04d} | '\n",
        "        #            f'Batch {batch_idx:04d}/{len(train_loader):04d} | '\n",
        "        #            f'Loss: {loss:.4f}')\n",
        "\n",
        "\n",
        "\n",
        "    print(\"training loss \",curr_loss/len(train_loader))  \n",
        "\n",
        "         \n",
        "    model.eval()\n",
        "\n",
        "    with torch.set_grad_enabled(False):\n",
        "        print(\"validation Loss\",validation_loss(model, valid_loader, DEVICE))\n",
        "        print(\"validation Accuracy\",infer(val_df))\n",
        "        if epoch%8==0:\n",
        "            print(\"The Training accuracy\",infer(train_df))\n",
        "        \n",
        "    print(f'Time elapsed: {(time.time() - start_time)/60:.2f} min')\n",
        "    \n",
        "print(f'Total Training Time: {(time.time() - start_time)/60:.2f} min')\n",
        "# print(f'Test accuracy: {compute_accuracy(model, test_loader, DEVICE):.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "59"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "len(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "torch.save(model.state_dict(), 'model_weights.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at t5-base were not used when initializing T5ForConditionalGeneration: ['decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight']\n",
            "- This IS expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BioQAModel(\n",
              "  (model): T5ForConditionalGeneration(\n",
              "    (shared): Embedding(32128, 768)\n",
              "    (encoder): T5Stack(\n",
              "      (embed_tokens): Embedding(32128, 768)\n",
              "      (block): ModuleList(\n",
              "        (0): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (relative_attention_bias): Embedding(32, 12)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (2): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (3): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (4): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (5): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (6): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (7): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (8): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (9): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (10): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (11): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_layer_norm): T5LayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (decoder): T5Stack(\n",
              "      (embed_tokens): Embedding(32128, 768)\n",
              "      (block): ModuleList(\n",
              "        (0): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (relative_attention_bias): Embedding(32, 12)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (2): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (3): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (4): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (5): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (6): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (7): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (8): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (9): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (10): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (11): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_layer_norm): T5LayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "model = BioQAModel() \n",
        "# optim = torch.optim.AdamW(model.parameters(),lr=0.0001 )\n",
        "model.to(DEVICE) # we do not specify pretrained=True, i.e. do not load default weights\n",
        "model.load_state_dict(torch.load('/data1/home/piyushmishra/DLNLP/model_weights.pth'))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIOml8Oe9kPb"
      },
      "source": [
        "## Generate answers for the questions in the validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "def infer2(dataframe):\n",
        "    count=0\n",
        "    output=[]\n",
        "    trueoutput=[]\n",
        "    for index in range(dataframe.shape[0]):\n",
        "        # if count!=index:\n",
        "        #     print(index)\n",
        "        sample_quest = dataframe.iloc[index]\n",
        "        truth=sample_quest[\"answer_text\"].split()\n",
        "        # print(truth)\n",
        "        no=sample_quest['Input Numbers'].split()\n",
        "        # print(no)\n",
        "        predicted=generate_answer(sample_quest).split()\n",
        "        actual=sample_quest['Output']\n",
        "        trueoutput.append(actual)\n",
        "        # print(predicted)\n",
        "        # bool1,val1=evaluate(truth,no)\n",
        "        bool2,val2=evaluate(predicted,no)\n",
        "        output.append(val2)\n",
        "\n",
        "        # print(bool1,val1)\n",
        "        # print(bool2,val2)\n",
        "        if(bool2==1):\n",
        "            if(round(val2,2)==round(actual,2)):\n",
        "                count=count+1\n",
        "            # else:\n",
        "            #     print(index)\n",
        "    return count/dataframe.shape[0],trueoutput,output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "a,b,c=infer2(val_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6122448979591837"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14.0 14.0\n",
            "30.0 25.0\n",
            "19.0 19.0\n",
            "90.0 225.0\n",
            "7.0 27.0\n",
            "336.0 1344.0\n",
            "3.0 3.0\n",
            "51.0 51.0\n",
            "52.0 4.0\n",
            "7.0 7.0\n",
            "208.0 208.0\n",
            "26.0 26.0\n",
            "20.0 20.0\n",
            "9.0 3.0\n",
            "6.0 6.0\n",
            "11.0 132.0\n",
            "300.0 300.0\n",
            "42.0 42.0\n",
            "35.0 35.0\n",
            "13.0 -13.0\n",
            "20.0 20.0\n",
            "41.0 32.0\n",
            "203.0 203.0\n",
            "43.07 43.07\n",
            "38.0 110.0\n",
            "6.0 150.0\n",
            "20.0 20.0\n",
            "2448.0 2448.0\n",
            "68.0 -12.0\n",
            "315.0 315.0\n",
            "14.0 14.0\n",
            "14.0 6.0\n",
            "612.0 612.0\n",
            "45552.0 45552.0\n",
            "10.0 10.0\n",
            "40.0 67.0\n",
            "60.0 3.0\n",
            "952.0 952.0\n",
            "3.0 23.0\n",
            "34.0 34.0\n",
            "136.0 136.0\n",
            "22.0 65.0\n",
            "61.0 61.0\n",
            "1.0 -17.0\n",
            "23.0 23.0\n",
            "96.0 96.0\n",
            "39.0 39.0\n",
            "34.0 6272.0\n",
            "8.0 8.0\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "for i in range(len(b)):\n",
        "    print(b[i],c[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "def infer3(dataframe):\n",
        "    output=[]\n",
        "    for index in range(dataframe.shape[0]):\n",
        "        # if count!=index:\n",
        "        #     print(index)\n",
        "        sample_quest = dataframe.iloc[index]\n",
        "        # print(truth)\n",
        "        no=sample_quest['Input Numbers'].split()\n",
        "        # print(no)\n",
        "        predicted=generate_answer(sample_quest).split()\n",
        "        # print(predicted)\n",
        "        # bool1,val1=evaluate(truth,no)\n",
        "        bool2,val2=evaluate(predicted,no)\n",
        "        output.append(val2)\n",
        "\n",
        "        # print(bool1,val1)\n",
        "        # print(bool2,val2)\n",
        "       \n",
        "            # else:\n",
        "            #     print(index)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "testdf = pd.read_excel('ArithOpsTestData1.xlsx')\n",
        "testdf.rename(columns = {'Description':'context','Question':'question'}, inplace = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>Input Numbers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>number0 red apples and number1 green apples ar...</td>\n",
              "      <td>how many apples are in the basket ?</td>\n",
              "      <td>7 2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ellen has number0 more balls than marin . mari...</td>\n",
              "      <td>how many balls does ellen have ?</td>\n",
              "      <td>6 9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>janet has number0 oranges and sharon has numbe...</td>\n",
              "      <td>how many oranges do janet and sharon have toge...</td>\n",
              "      <td>9 7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>allan brought number0 balloons and jake brough...</td>\n",
              "      <td>how many balloons did allan and jake have in t...</td>\n",
              "      <td>2 4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>adam has number0 more apples than jackie . jac...</td>\n",
              "      <td>how many apples does adam have ?</td>\n",
              "      <td>5 9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             context  \\\n",
              "0  number0 red apples and number1 green apples ar...   \n",
              "1  ellen has number0 more balls than marin . mari...   \n",
              "2  janet has number0 oranges and sharon has numbe...   \n",
              "3  allan brought number0 balloons and jake brough...   \n",
              "4  adam has number0 more apples than jackie . jac...   \n",
              "\n",
              "                                            question Input Numbers  \n",
              "0                how many apples are in the basket ?           7 2  \n",
              "1                   how many balls does ellen have ?           6 9  \n",
              "2  how many oranges do janet and sharon have toge...           9 7  \n",
              "3  how many balloons did allan and jake have in t...           2 4  \n",
              "4                   how many apples does adam have ?           5 9  "
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "testdf.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "final_output=infer3(testdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[9.0,\n",
              " -3.0,\n",
              " 16.0,\n",
              " 6.0,\n",
              " -4.0,\n",
              " -3.0,\n",
              " 8.0,\n",
              " -4.0,\n",
              " 18.0,\n",
              " 11.0,\n",
              " 24.0,\n",
              " 19.0,\n",
              " 45.0,\n",
              " 2.0,\n",
              " 8.0,\n",
              " -7.0,\n",
              " -3.0,\n",
              " -7.0,\n",
              " -12.0,\n",
              " 6.0,\n",
              " 5.0,\n",
              " -4.0,\n",
              " 3.0,\n",
              " 1.0,\n",
              " 5.0,\n",
              " 1.0,\n",
              " 3.0,\n",
              " 38.0,\n",
              " 38.0,\n",
              " 13.0,\n",
              " 46.0,\n",
              " 11.0,\n",
              " 7.0,\n",
              " 5.0,\n",
              " 6.0,\n",
              " 4.0,\n",
              " 6.0,\n",
              " 11.0,\n",
              " 7.0,\n",
              " 18.0,\n",
              " 7.0,\n",
              " 7.0,\n",
              " 7.0,\n",
              " 5.0,\n",
              " 28.0,\n",
              " 8.0,\n",
              " 38.0,\n",
              " 929.0,\n",
              " 62.0,\n",
              " 46.0,\n",
              " 20.0,\n",
              " 79.0,\n",
              " 67.0,\n",
              " 14.0,\n",
              " 9.0,\n",
              " -6.0,\n",
              " -23.0,\n",
              " 17.0,\n",
              " -32.0,\n",
              " 22.0,\n",
              " 42.0,\n",
              " 35.0,\n",
              " 19.0,\n",
              " 128.0,\n",
              " 57.0,\n",
              " 286.0,\n",
              " 41.0,\n",
              " 0.75,\n",
              " 300.0,\n",
              " 10.0,\n",
              " 58.0,\n",
              " 4.0,\n",
              " 21.0,\n",
              " 0.1111111111111111,\n",
              " 20.0,\n",
              " 15.0,\n",
              " 115.0,\n",
              " 24.0,\n",
              " 0.06666666666666667,\n",
              " 190.0,\n",
              " 311.0,\n",
              " 164.0,\n",
              " 117.0,\n",
              " 103.0,\n",
              " 139.0,\n",
              " 352.0,\n",
              " -15.0,\n",
              " -188.0,\n",
              " 100.0,\n",
              " 55.0,\n",
              " 82.0,\n",
              " 828.0,\n",
              " 12.0,\n",
              " 0.3333333333333333,\n",
              " 45.0,\n",
              " 40.0,\n",
              " 54.0,\n",
              " 56.0,\n",
              " 12.0,\n",
              " 8.0,\n",
              " 30.0,\n",
              " 72.0,\n",
              " 3285.0,\n",
              " 10.0,\n",
              " 0.08333333333333333,\n",
              " 7.0,\n",
              " 9.0,\n",
              " 60.0,\n",
              " 0.16666666666666666,\n",
              " 0.25,\n",
              " 20.0,\n",
              " 0.14285714285714285,\n",
              " 5.0,\n",
              " 0.1111111111111111,\n",
              " 432.0,\n",
              " 6003.0,\n",
              " 2250.0,\n",
              " 20.0,\n",
              " 7.0,\n",
              " 2205.0,\n",
              " 486.0,\n",
              " 372.0,\n",
              " 0.2222222222222222,\n",
              " 1035.0,\n",
              " -7.0,\n",
              " 40.0,\n",
              " 28.0,\n",
              " 0.14,\n",
              " 6.625,\n",
              " 19.0,\n",
              " 16.153846153846153,\n",
              " 14.57,\n",
              " -8.0,\n",
              " -7.0,\n",
              " 8.0,\n",
              " 20.0,\n",
              " 60.0,\n",
              " -11.0,\n",
              " 60.0,\n",
              " 73.0,\n",
              " 93.0,\n",
              " 9.0,\n",
              " 48.0,\n",
              " 40.0,\n",
              " -18.0,\n",
              " 42.0,\n",
              " 78.0,\n",
              " 30.0,\n",
              " 126.0,\n",
              " 8.0,\n",
              " 50.0,\n",
              " 137.0,\n",
              " 11760.0,\n",
              " 64.0,\n",
              " -11.0,\n",
              " 15.0,\n",
              " 10.0,\n",
              " -31.0,\n",
              " -67.0,\n",
              " -12.0,\n",
              " 49.0,\n",
              " -4.0,\n",
              " 196.0,\n",
              " 2480.0,\n",
              " 65.0,\n",
              " 48.0,\n",
              " 1125.0,\n",
              " 24.0,\n",
              " 6.0,\n",
              " 9.0,\n",
              " 6.0,\n",
              " 8.0,\n",
              " 7.0,\n",
              " 24.0,\n",
              " 91.0,\n",
              " 3.0,\n",
              " 17.0,\n",
              " 512.0,\n",
              " 21.0,\n",
              " 4.0,\n",
              " 2.0,\n",
              " 13.0,\n",
              " 3.0,\n",
              " 7.0,\n",
              " 6.0,\n",
              " 17.0,\n",
              " 10.0,\n",
              " 11.0,\n",
              " 2.0,\n",
              " 0.2,\n",
              " 8.0,\n",
              " 8.0,\n",
              " 5.0,\n",
              " 9.0,\n",
              " 4.0,\n",
              " 6.0,\n",
              " 9.0,\n",
              " 11.0,\n",
              " 12.0,\n",
              " 12.0,\n",
              " 5.0,\n",
              " 11.0,\n",
              " 25.0,\n",
              " 98.0,\n",
              " 7.0,\n",
              " 2.0,\n",
              " 13.0,\n",
              " 11.0,\n",
              " 100.0,\n",
              " 29.0,\n",
              " 7.0,\n",
              " 12.0,\n",
              " 6.0,\n",
              " -10.0,\n",
              " 34.0,\n",
              " 84.0,\n",
              " 11.0,\n",
              " -14.0,\n",
              " 83.0,\n",
              " 39.0,\n",
              " 87.0,\n",
              " 9.0,\n",
              " 9.0,\n",
              " 21.0,\n",
              " 16.0,\n",
              " 5.0,\n",
              " 11.0,\n",
              " 175.0,\n",
              " 7.0,\n",
              " 27.0,\n",
              " 28.0,\n",
              " 12.333333333333334,\n",
              " 54.0,\n",
              " 2.8,\n",
              " 12.0,\n",
              " 600.0,\n",
              " 76.0,\n",
              " 539.0]"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "final_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import openpyxl\n",
        "\n",
        "df = pd.DataFrame(final_output,columns=['Piyush Kumar Mishra'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Piyush Kumar Mishra</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>2.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>234</th>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>235</th>\n",
              "      <td>600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>236</th>\n",
              "      <td>76.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237</th>\n",
              "      <td>539.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>238 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Piyush Kumar Mishra\n",
              "0                    9.0\n",
              "1                   -3.0\n",
              "2                   16.0\n",
              "3                    6.0\n",
              "4                   -4.0\n",
              "..                   ...\n",
              "233                  2.8\n",
              "234                 12.0\n",
              "235                600.0\n",
              "236                 76.0\n",
              "237                539.0\n",
              "\n",
              "[238 rows x 1 columns]"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "df.to_excel('Piyush3.xlsx', index=False, header=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Piyush Kumar Mishra</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Piyush Kumar Mishra\n",
              "0                   11\n",
              "1                   21\n",
              "2                   31"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df2 = pd.read_excel('/data1/home/piyushmishra/DLNLP/Assignment_5b/Piyush3.xlsx')\n",
        "df3=pd.read_excel('/data1/home/piyushmishra/DLNLP/Assignment_5b/ArithOpsTestData1.xlsx')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Piyush Kumar Mishra    15.0\n",
              "Name: 1, dtype: float64"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "df2.iloc[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "count=0\n",
        "for i in range(df3.shape[0]):\n",
        "    if(df2.iloc[i]['Piyush Kumar Mishra']==df3.iloc[i]['Output']):\n",
        "        count=count+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5546218487394958"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "count/df3.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['+', 'number0', 'number1']\n",
            "['35', '56']\n",
            "['+', 'number0', 'number1']\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "sample_quest = train_df.iloc[0]\n",
        "truth=sample_quest[\"answer_text\"].split()\n",
        "print(truth)\n",
        "no=sample_quest['Input Numbers'].split()\n",
        "print(no)\n",
        "predicted=generate_answer(sample_quest).split()\n",
        "actual=sample_quest['Output']\n",
        "print(predicted)\n",
        "bool1,val1=evaluate(truth,no)\n",
        "bool2,val2=evaluate(predicted,no)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "list index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m/data1/home/piyushmishra/DLNLP/Assignment_5b/equation_solver.ipynb Cell 87\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.192.12.63/data1/home/piyushmishra/DLNLP/Assignment_5b/equation_solver.ipynb#Y233sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m predicted[\u001b[39m3\u001b[39;49m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39misdigit()\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "predicted[3][-1].isdigit()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
